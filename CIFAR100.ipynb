{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR100.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwinDeshpande96/Hierarchical-Softmax/blob/master/CIFAR100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PuLjjeUj7f_",
        "colab_type": "code",
        "outputId": "8f62d1d6-1fd5-49ec-cc8c-8e2c2711f297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 19s 0us/step\n",
            "169017344/169001437 [==============================] - 19s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-5kmb0RkVIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization, Layer\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import time as t\n",
        "import itertools as it\n",
        "from random import shuffle\n",
        "from copy import copy\n",
        "\n",
        "\n",
        "K.set_image_dim_ordering('th')\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nx_nnXikvlq",
        "colab_type": "code",
        "outputId": "1822ba31-ae9e-4295-e417-379e8b2ceccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train = x_train.astype('float32').reshape((x_train.shape[0], 3, 32, 32))/255.\n",
        "x_test = x_test.astype('float32').reshape((x_test.shape[0], 3, 32, 32))/255.\n",
        "#y_train = -K.log(np_utils.to_categorical(y_train))\n",
        "#y_test = -K.log(np_utils.to_categorical(y_test))\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "print x_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3, 32, 32) (50000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUCStfh18ai3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class TreeTools:\n",
        "    def __init__(self):\n",
        "        #memoization for _count_nodes functions\n",
        "        self._count_nodes_dict = {}\n",
        "        self.index = 0\n",
        "    def _get_paths(self, tree, i=0, i_list=[]):\n",
        "        key = ','.join(str(x) for x in i_list[:])\n",
        "        yield key, i_list\n",
        "        self.index = self.index + 1\n",
        "                   \n",
        "        for subtree in tree:\n",
        "            if type(subtree) == list:\n",
        "                for node, ilist in self._get_paths(subtree, i=self.index, i_list=i_list[:]+[self.index]):\n",
        "                    if (type(subtree[0]) == int):\n",
        "                        node = \"e\".join(str(n) for n in subtree)\n",
        "                    \n",
        "                    yield node, ilist\n",
        "            else:\n",
        "                if type(tree[0]) == list:\n",
        "                    yield \"e\"+str(subtree), i_list            \n",
        "    def _get_subtrees(self, tree):\n",
        "        yield tree\n",
        "        for subtree in tree:\n",
        "            if type(subtree) == list:\n",
        "                for x in self._get_subtrees(subtree):\n",
        "                    yield x\n",
        "\n",
        "    # Returns pairs of paths and leafves of a tree\n",
        "    def _get_leaves_paths(self, tree, i_list=[]):\n",
        "        for i, subtree in enumerate(tree):\n",
        "            if type(subtree) == list:\n",
        "                for path, value in self._get_leaves_paths(subtree):\n",
        "                    yield [i] + path, value\n",
        "            else:\n",
        "                yield [i], subtree\n",
        "    \n",
        "    # Returns the number of nodes in a tree (not including root)\n",
        "    def _count_nodes(self, tree):\n",
        "        if id(tree) in self._count_nodes_dict:\n",
        "            return self._count_nodes_dict[id(tree)]\n",
        "        size = 0\n",
        "        for node in tree:\n",
        "            if type(node) == list:\n",
        "                size += 1 + self._count_nodes(node)\n",
        "        self._count_nodes_dict[id(self._count_nodes_dict)] = size\n",
        "        return size\n",
        "\n",
        "\n",
        "    # Returns all the nodes in a path\n",
        "    def _get_nodes(self, tree, path):\n",
        "        next_node = 0\n",
        "        nodes = []\n",
        "        for decision in path:\n",
        "            nodes.append(next_node)\n",
        "            next_node += 1 + self._count_nodes(tree[:decision])\n",
        "            tree = tree[decision]\n",
        "        return nodes\n",
        "    def _print_tree(tree):\n",
        "        print tree\n",
        "        for subtree in tree:\n",
        "            self._print_tree(subtree)\n",
        "\n",
        "# turns a list to a binary tree\n",
        "def make_tree(output_dim):\n",
        "    outputs = list(range(output_dim))\n",
        "    outputs = copy(outputs)\n",
        "    shuffle(outputs)\n",
        "    \n",
        "    while len(outputs) > 2:\n",
        "        temp_outputs = []\n",
        "        for i in range(0, len(outputs), 2):\n",
        "            if len(outputs) - (i+1) > 0:\n",
        "                temp_outputs.append([outputs[i], outputs[i+1]])\n",
        "            else:\n",
        "                temp_outputs.append(outputs[i])\n",
        "        outputs = temp_outputs\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eQag8vRi_yU",
        "colab_type": "code",
        "outputId": "b39ea334-a338-4989-bc96-300c12982b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "tree = random_binary_full_tree(list(range(10)))\n",
        "treetool = TreeTools()\n",
        "for ilist, node in treetool._get_paths(tree):\n",
        "    \n",
        "    print ilist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1\n",
            "1,2\n",
            "8e4\n",
            "6e7\n",
            "1,5\n",
            "2e0\n",
            "3e1\n",
            "9e5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jiZO7fsI52i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "class HSM(Layer):\n",
        "\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super(HSM, self).__init__(**kwargs)\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.tree = make_tree(output_dim)\n",
        "        '''\n",
        "        self.node_vectors = {}\n",
        "        \n",
        "        for i  in range(1, self.output_dim):\n",
        "            self.node_vectors[i] = self.add_weight(name=\"node_\"+str(i),\n",
        "                                                   shape=(len(self.tree), len(self.tree)),\n",
        "                                                   initializer='uniform',\n",
        "                                                   trainable=True)\n",
        "        '''\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        \n",
        "        self.kernel = self.add_weight(name='kernel', \n",
        "                                      shape=(self.output_dim, input_shape[1], len(self.tree)),\n",
        "                                      initializer='uniform',\n",
        "                                      trainable=True)\n",
        "        self.bias = self.add_weight(name='bias', \n",
        "                                      shape=(self.output_dim,),\n",
        "                                      initializer='zeros',\n",
        "                                      trainable=True)\n",
        "        \n",
        "        super(HSM, self).build(input_shape)  # Be sure to call this at the end\n",
        "             \n",
        "    def call(self, x):\n",
        "        x = K.dot(x, self.kernel)\n",
        "        print x\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLKYRg0tI7PZ",
        "colab_type": "code",
        "outputId": "0d86b5b9-27ba-431f-c760-345253f9914b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "x = tf.convert_to_tensor([i for i in range(12)], preferred_dtype=tf.dtypes.float32)\n",
        "w = tf.convert_to_tensor(np.ones((10,12,2)), preferred_dtype=tf.dtypes.float32)\n",
        "print sess.run(K.dot(x,w))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[66. 66.]\n",
            " [66. 66.]\n",
            " [66. 66.]\n",
            " [66. 66.]\n",
            " [66. 66.]\n",
            " [66. 66.]\n",
            " [66. 66.]\n",
            " [66. 66.]\n",
            " [66. 66.]\n",
            " [66. 66.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTn_ON9UJZAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2HxsIbDkzyH",
        "colab_type": "code",
        "outputId": "6f50e29f-d181-49f5-9448-650ab12e4cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(3, 32, 32), padding='same', activation='relu', name='conv1'))\n",
        "#model.add(BatchNormalization( name='bn1'))\n",
        "model.add(MaxPooling2D(pool_size=(17, 17) , name='max1'))\n",
        "#model.add(Conv2D(16, (5, 5), activation='relu', name='conv2'))\n",
        "#model.add(BatchNormalization( name='bn2'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), name='max2'))\n",
        "#model.add(Dropout(0.2, name='drop1'))\n",
        "model.add(Flatten(name='flat1'))\n",
        "model.add(Dense(128, name='dense1'))\n",
        "#model.add(Dense(output_dim=num_classes, activation='softmax', name='dense2'))\n",
        "hsm1 = HSM(output_dim=100, name='hsm1')\n",
        "model.add(hsm1)\n",
        "#model.add(Activation('softmax'))\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(1.0e-3), metrics=['accuracy'])\n",
        "model.summary()\n",
        "#print model.trainable_weights\n",
        "#print model.non_trainable_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"hsm1_15/Reshape_2:0\", shape=(?, 100, 2), dtype=float32)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 32, 32, 32)        2432      \n",
            "_________________________________________________________________\n",
            "max1 (MaxPooling2D)          (None, 32, 1, 1)          0         \n",
            "_________________________________________________________________\n",
            "flat1 (Flatten)              (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 128)               4224      \n",
            "_________________________________________________________________\n",
            "hsm1 (HSM)                   (None, 100)               25700     \n",
            "=================================================================\n",
            "Total params: 32,356\n",
            "Trainable params: 32,356\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74tqnNO0oY-l",
        "colab_type": "code",
        "outputId": "6ff84ade-29b3-44c3-b5de-c3812087ea33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        }
      },
      "source": [
        "# build the model\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta=1.5e-5, patience=5, verbose=1, mode='min')\n",
        "    #ModelCheckpoint(filepath, save_best_only=True,  save_weights_only=False, monitor='val_loss', mode='min', verbose=1)\n",
        "]\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=callbacks, epochs=50, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            " - 3s - loss: 4.3655 - acc: 0.0420 - val_loss: 4.1263 - val_acc: 0.0736\n",
            "Epoch 2/50\n",
            " - 2s - loss: 3.9977 - acc: 0.0934 - val_loss: 3.9185 - val_acc: 0.1083\n",
            "Epoch 3/50\n",
            " - 2s - loss: 3.8272 - acc: 0.1210 - val_loss: 3.7888 - val_acc: 0.1287\n",
            "Epoch 4/50\n",
            " - 2s - loss: 3.7274 - acc: 0.1358 - val_loss: 3.7219 - val_acc: 0.1390\n",
            "Epoch 5/50\n",
            " - 2s - loss: 3.6666 - acc: 0.1473 - val_loss: 3.6704 - val_acc: 0.1489\n",
            "Epoch 6/50\n",
            " - 2s - loss: 3.6201 - acc: 0.1558 - val_loss: 3.6518 - val_acc: 0.1546\n",
            "Epoch 7/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-d0d85d19014a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Final evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz_qMCGrmPIj",
        "colab_type": "text"
      },
      "source": [
        "# rough"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4JcdZjuAqse",
        "colab_type": "code",
        "outputId": "39f4a5e3-fd42-4143-9208-e8030a321673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "number_of_leaves = 100\n",
        "tree1 = random_binary_full_tree(list(range(number_of_leaves)))\n",
        "tt = TreeTools()\n",
        "root = tf.convert_to_tensor(np.random.rand(number_of_leaves,2).astype('float32'))\n",
        "node_vectors = {0: root}\n",
        "saved_weights = {}\n",
        "x = tf.convert_to_tensor(np.random.rand(1, number_of_leaves).astype('float32'))\n",
        "\n",
        "\n",
        "for i  in range(1, number_of_leaves):\n",
        "    node_vectors[i] = tf.convert_to_tensor(np.random.uniform(0.0,1.0, 4).reshape((2,2)), preferred_dtype='float32')\n",
        "\n",
        "\n",
        "def node_prob(x, path):\n",
        "    key = \",\".join(str(n) for n in path)\n",
        "    if key in saved_weights.keys():\n",
        "        #print \"Found: \", key\n",
        "        return saved_weights[key]\n",
        "    else:\n",
        "        if len(path) == 1:\n",
        "            #print \"Compute: \", x, \"*\", node_vectors[path[0]] \n",
        "            return K.softmax(K.dot(x, node_vectors[path[0]]))\n",
        "        a = node_prob(x, path[:-1])\n",
        "        b = node_vectors[path[-1]]\n",
        "        #print \"Compute: \", a, \"*\", b\n",
        "        return K.softmax(K.dot(a, b))\n",
        "\n",
        "sess = tf.Session()\n",
        "leaf_to_decision = {}\n",
        "for path, value in tt._get_leaves_paths(tree1):\n",
        "    leaf_to_decision[value] = path\n",
        "\n",
        "def get_marginal_prob(path, decision):\n",
        "    prob = tf.zeros([1,1])\n",
        "    #prob = tf.ones([1,1])\n",
        "    for i in range(0,len(path)):\n",
        "        key = \",\".join(str(node) for node in path[:i+1])\n",
        "        d = decision[i]\n",
        "        p = tf.slice(saved_weights[key], [0,d], [1,1])\n",
        "        l = tf.log(p)\n",
        "        #print d, path[i], sess.run(saved_weights[key]), sess.run(p), sess.run(l)\n",
        "        prob = prob + -1*(l)\n",
        "        #prob *= p\n",
        "    #print sess.run(prob)\n",
        "    return prob\n",
        "output = [tf.zeros([1,1], dtype=tf.dtypes.float32) for repeater in range(number_of_leaves)]\n",
        "#output = []\n",
        "start = t.time()\n",
        "for node, path in tt._get_paths(tree1):\n",
        "    #print node, \"\\t\", path\n",
        "    \n",
        "    key = \",\".join(str(p) for p in path)\n",
        "    temp = node_prob(x, path)\n",
        "    \n",
        "    #print temp.get_shape(), \"\\t\", node, \"\\t\\t\", path\n",
        "    saved_weights[key] = temp\n",
        "    \n",
        "    if 'e' in node:\n",
        "        if node.startswith('e'):\n",
        "            last_leaf = int(node[1:])\n",
        "            probability = get_marginal_prob(path, leaf_to_decision[last_leaf])\n",
        "            #print \"p(\", last_leaf, \")= \", sess.run(probability)\n",
        "            #output.append(probability )\n",
        "            output[last_leaf] =  probability\n",
        "            continue\n",
        "        end_node = [int(leaf) for leaf in node.split('e')]\n",
        "        for leaves in end_node:\n",
        "            #print \"\"\n",
        "            probability = get_marginal_prob(path, leaf_to_decision[leaves])\n",
        "            #print \"p(\", leaves, \")= \", sess.run(probability)\n",
        "            #output.append(probability )\n",
        "            output[leaves] =  probability\n",
        "    #print \"\"\n",
        "tt.index = 0      \n",
        "time_taken = t.time() - start\n",
        "output = tf.concat(output, axis=1)\n",
        "\n",
        "print \"Time Taken: \", time_taken, \"s\\nNumber of Classes: \", number_of_leaves\n",
        "#print sess.run(output)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time Taken:  2.43883395195 s\n",
            "Number of Classes:  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe4uPn9W_2Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super(MyLayer, self).__init__(**kwargs)\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self._tree_tools = TreeTools()\n",
        "        self.tree = random_binary_full_tree(list(range(output_dim)))\n",
        "        #print self.tree\n",
        "        self.saved_weights = {}\n",
        "        self.leaf_to_decision = {}\n",
        "        for path, value in self._tree_tools._get_leaves_paths(self.tree):\n",
        "            self.leaf_to_decision[value] = path\n",
        "        '''\n",
        "        leaf_to_path = {}\n",
        "        for path, value in self._tree_tools._get_leaves_paths(tree):\n",
        "            nodes = self._tree_tools._get_nodes(tree, path)\n",
        "            leaf_to_path[int(value)] = path, nodes\n",
        "        self.leaf_to_path = leaf_to_path\n",
        "        \n",
        "        self.str2weight = {}\n",
        "        for i, subtree in enumerate(self._tree_tools._get_subtrees(tree)):\n",
        "            self.str2weight[\"softmax_node_\"+str(i)+\"_w\"] = self.add_weight(name=\"softmax_node_\"+str(i)+\"_w\",\n",
        "                                                                          shape=(len(subtree), output_dim),\n",
        "                                                                          initializer='uniform',\n",
        "                                                                          trainable=True)\n",
        "            self.str2weight[\"softmax_node_\" + str(i) + \"_b\"] = self.add_weight(name=\"softmax_node_\"+str(i)+\"_b\",\n",
        "                                                                          shape=(len(subtree),1),\n",
        "                                                                          initializer='zeros',\n",
        "                                                                          trainable=True)\n",
        "        '''\n",
        "        #print \"Length of the first layer:\", len(self.tree)\n",
        "    def build(self, input_shape):\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        \n",
        "        self.kernel = self.add_weight(name='kernel', \n",
        "                                      shape=(input_shape[1], self.output_dim),\n",
        "                                      initializer='uniform',\n",
        "                                      trainable=True)\n",
        "        self.bias = self.add_weight(name='bias', \n",
        "                                      shape=(self.output_dim,),\n",
        "                                      initializer='uniform',\n",
        "                                      trainable=True)\n",
        "\n",
        "        self.node_vectors = {0: self.add_weight(name=\"root_node\",\n",
        "                                                   shape=(self.output_dim, len(self.tree)),\n",
        "                                                   initializer='uniform',\n",
        "                                                   trainable=True)}\n",
        "        \n",
        "        for i  in range(1, self.output_dim):\n",
        "            self.node_vectors[i] = self.add_weight(name=\"node_\"+str(i),\n",
        "                                                   shape=(len(self.tree), len(self.tree)),\n",
        "                                                   initializer='uniform',\n",
        "                                                   trainable=True)\n",
        "        \n",
        "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "    def get_marginal_prob(self, path, decision):\n",
        "        #prob = tf.zeros([1,1])\n",
        "        prob = tf.ones([1,1])\n",
        "        for i in range(0,len(path)):\n",
        "            key = \",\".join(str(node) for node in path[:i+1])\n",
        "            d = decision[i]\n",
        "            p = tf.slice(self.saved_weights[key], [0,d], [1,1])\n",
        "            #l = tf.log(p)\n",
        "            #prob = prob + -1*(l)\n",
        "            prob *= p\n",
        "            \n",
        "            #print d, path[i], sess.run(self.saved_weights[key]), sess.run(p), sess.run(l)\n",
        "        #print sess.run(prob)\n",
        "        return prob\n",
        "    def node_prob(self, x, path):\n",
        "        key = \",\".join(str(n) for n in path)\n",
        "        if key in self.saved_weights.keys():\n",
        "            #print \"Found: \", key, \"\\n\\t\",\n",
        "            return self.saved_weights[key]\n",
        "        else:\n",
        "            if len(path) == 1:\n",
        "                \n",
        "                #print \"Compute: \", x, \"*\", self.node_vectors[path[0]]\n",
        "                \n",
        "                return K.softmax(K.dot(x, self.node_vectors[path[0]]))\n",
        "            a = self.node_prob(x, path[:-1])\n",
        "            b = self.node_vectors[path[-1]]\n",
        "            #print \"Compute: \", a, \"*\", b\n",
        "            return K.softmax(K.dot(a, b))\n",
        "                \n",
        "    def call(self, x):\n",
        "        x = K.dot(x, self.kernel)\n",
        "        x = x + self.bias\n",
        "        #self.node_vectors = {0: K.softmax(K.dot(x, self.root))}\n",
        "        \n",
        "        '''\n",
        "        \n",
        "        output = [tf.zeros([1,1], dtype=tf.dtypes.float32) for repeater in range(self.output_dim)]\n",
        "        self.saved_weights = {}\n",
        "        for node, path in self._tree_tools._get_paths(self.tree):\n",
        "            key = \",\".join(str(p) for p in path)\n",
        "\n",
        "            #print node, \"\\t\", path\n",
        "            self.saved_weights[key] = self.node_prob(x, path)\n",
        "            if 'e' in node:\n",
        "                if node.startswith('e'):\n",
        "                    last_leaf = int(node[1:])\n",
        "                    probability = self.get_marginal_prob(path, self.leaf_to_decision[last_leaf])\n",
        "                    #print \"p(\", last_leaf, \")= \", sess.run(probability)\n",
        "                    #output.append(probability )\n",
        "                    output[last_leaf] =  probability\n",
        "                    continue\n",
        "                end_node = [int(leaf) for leaf in node.split('e')]\n",
        "                for leaves in end_node:\n",
        "                    #print \"\"\n",
        "                    probability = self.get_marginal_prob(path, self.leaf_to_decision[leaves])\n",
        "                    #print \"p(\", leaves, \")= \", sess.run(probability)\n",
        "                    #output.append(probability )\n",
        "                    output[leaves] =  probability\n",
        "        self._tree_tools.index = 0\n",
        "        output = tf.concat(output, axis=1)\n",
        "        \n",
        "        return output\n",
        "        \n",
        "        '''\n",
        "        '''\n",
        "        #loss = tf.convert_to_tensor(np.random.rand(100,).astype('float32'))\n",
        "        \n",
        "        loss = []\n",
        "        \n",
        "        for value in self.leaf_to_path:\n",
        "            log_loss = tf.convert_to_tensor([0.0])\n",
        "            path, node = self.leaf_to_path[value]\n",
        "            #print \"\\n\"\n",
        "            #print path, node\n",
        "            for i in range(len(path)):\n",
        "                p = path[i]\n",
        "                n = node[i]\n",
        "                #print p,n\n",
        "                vec = self.str2weight[\"softmax_node_\"+str(n)+\"_w\"]\n",
        "                b = self.str2weight[\"softmax_node_\" + str(n) + \"_b\"]\n",
        "                \n",
        "                \n",
        "                preds = softmax(vec,x,b)\n",
        "                node_loss = -1 * K.log(tf.slice(preds, [p,0], [1,1]))\n",
        "                log_loss = log_loss + node_loss\n",
        "                \n",
        "            loss.append(log_loss)  \n",
        "                \n",
        "        \n",
        "        return tf.reshape(loss, [100,1])\n",
        "        '''\n",
        "        return K.softmax(x)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcVn8Qx7sUa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def softmax2(vec, x1, b):\n",
        "    \"\"\"Softmax activation function.\n",
        "    # Arguments\n",
        "        x: Input tensor.\n",
        "        axis: Integer, axis along which the softmax normalization is applied.\n",
        "    # Returns\n",
        "        Tensor, output of softmax transformation.\n",
        "    # Raises\n",
        "        ValueError: In case `dim(x) == 1`.\n",
        "    \"\"\"\n",
        "    vec = tf.convert_to_tensor(vec)\n",
        "    x1 = tf.reshape(x1, [128,1])\n",
        "    #x1 = tf.convert_to_tensor(x1)\n",
        "    x = K.dot(vec, x1)\n",
        "    x = tf.math.add(x, b)\n",
        "    \n",
        "    e = K.exp(x)\n",
        "    s = K.sum(e)\n",
        "    #sess = tf.Session()\n",
        "    \n",
        "    return e/s\n",
        "#get_custom_objects().update({'custom_activation': Activation(softmax2)})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsfb-2shmoHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "w1 = tf.convert_to_tensor([[20,2,3], [1,2,2]], preferred_dtype='float32')\n",
        "x1 = tf.convert_to_tensor([[1],[1],[1]], preferred_dtype='float32')\n",
        "b1 = tf.convert_to_tensor([[1],[2]], preferred_dtype='float32')\n",
        "res = K.dot(w1/20, x1)\n",
        "x = tf.math.add(res, b1/2)/20\n",
        "e = K.exp(x)\n",
        "s = K.sum(e)\n",
        "val = tf.slice(b1, [1,0], [1,1])\n",
        "sess = tf.Session()\n",
        "#print sess.run(val)\n",
        "var = tf.convert_to_tensor([0.0])\n",
        "\n",
        "var = var + val\n",
        "l = []\n",
        "print sess.run(var)\n",
        "l.append(var)\n",
        "var = var + val\n",
        "print sess.run(var)\n",
        "l.append(var)\n",
        "print "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRimnc4B1rFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree = random_binary_full_tree(list(range(10)))\n",
        "tree_tools = TreeTools()\n",
        "leaf_to_path = {}\n",
        "for path, value in tree_tools._get_leaves_paths(tree):\n",
        "    nodes = tree_tools._get_nodes(tree, path)\n",
        "    leaf_to_path[int(value)] = path, nodes\n",
        "str2weight = {}\n",
        "for i, subtree in enumerate(tree_tools._get_subtrees(tree)):\n",
        "    str2weight[\"softmax_node_\"+str(i)+\"_w\"] = np.random.rand(len(subtree),128)\n",
        "    str2weight[\"softmax_node_\"+str(i)+\"_b\"] = np.random.rand(1, 128)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ4FauEV4dTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for value in leaf_to_path:\n",
        "    print value\n",
        "    path, node = leaf_to_path[value]\n",
        "    node_probs = []\n",
        "    for p, n in zip(path, nodes):\n",
        "        w = str2weight[\"softmax_node_\"+str(n)+\"_w\"]\n",
        "        b = str2weight[\"softmax_node_\"+str(n)+\"_b\"]\n",
        "        inp = np.dot(w, x) + b\n",
        "        node_probs.append(softmax(inp))\n",
        "    print node_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvu-qgBnQObk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x = np.random.rand(128,)\n",
        "\n",
        "#define a variable to hold normal random values \n",
        "normal_rv = tf.Variable( tf.truncated_normal([2,3],stddev = 0.1))\n",
        "\n",
        "#initialize the variable\n",
        "init_op = tf.initialize_all_variables()\n",
        "\n",
        "#run the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op) #execute init_op\n",
        "    #print the random values that we sample\n",
        "    print (sess.run(normal_rv))\n",
        "    \n",
        "for value in leaf_to_path:\n",
        "    print value\n",
        "    loss = []\n",
        "    path, node = leaf_to_path[value]\n",
        "    print path, \"\\n\", node\n",
        "    print len(node[0:])\n",
        "    \n",
        "    \n",
        "    for n in range(4):\n",
        "        print \"hey\"\n",
        "        w = np.random.rand(2, 128)\n",
        "        b = np.random.rand(2,)\n",
        "        left = np.sum(w[0]*x.copy()) + b[0]\n",
        "        right = np.sum(w[1]*x.copy()) + b[1]\n",
        "        inp = np.array([left, right])\n",
        "        print inp\n",
        "        preds = softmax(inp)\n",
        "        tf.Print(preds)\n",
        "    \n",
        "    print \"\\n\"    \n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dAf60f_gQwk",
        "colab_type": "code",
        "outputId": "7d509d19-7c09-4fc2-e7b3-51d33c3b139d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "x = tf.convert_to_tensor([3,2], preferred_dtype=tf.dtypes.float32)\n",
        "#x1 = K.exp(x)\n",
        "y = tf.convert_to_tensor([[[2,2], [3,3]],\n",
        "                          [[2,1], [4,3]]], preferred_dtype=tf.dtypes.float32)\n",
        "print 'yshape', y.get_shape()\n",
        "sess = tf.Session()\n",
        "print 'x', sess.run(x)\n",
        "#print tf.Session().run(x1)\n",
        "print 'y', sess.run(y)\n",
        "intermediate = K.pow(x,y)\n",
        "print 'pow', sess.run(intermediate)\n",
        "es = tf.reduce_prod(intermediate, axis=1)\n",
        "print 'e', sess.run(es)\n",
        "print sess.run(es/tf.reshape(tf.reduce_sum(es, axis=1), [2,1]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yshape (2, 2, 2)\n",
            "x [3. 2.]\n",
            "y [[[2. 2.]\n",
            "  [3. 3.]]\n",
            "\n",
            " [[2. 1.]\n",
            "  [4. 3.]]]\n",
            "pow [[[ 9.  4.]\n",
            "  [27.  8.]]\n",
            "\n",
            " [[ 9.  2.]\n",
            "  [81.  8.]]]\n",
            "e [[243.  32.]\n",
            " [729.  16.]]\n",
            "[[0.88363636 0.11636364]\n",
            " [0.9785235  0.02147651]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG1IjDu8ShHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt = TreeTools()\n",
        "\n",
        "        self.tree = random_binary_full_tree(list(range(output_dim)))\n",
        "        self.leaf_path = {}\n",
        "        for node, path in tt._get_paths(self.tree):\n",
        "            if 'e' in node:\n",
        "                if node.startswith('e'):\n",
        "                    self.leaf_path[int(node[1:])] = path\n",
        "                for l in [int(leaf) for leaf in node.split('e')]:\n",
        "                    self.leaf_path[l] = path\n",
        "        self.categorical = {}\n",
        "for path, leaf in tt._get_leaves_paths(self.tree):\n",
        "            self.categorical[leaf] = np_utils.to_categorical(path, num_classes=2)\n",
        "        \n",
        "self.root = self.add_weight(name=\"root_node\",\n",
        "                                    shape=(self.output_dim, len(self.tree)),\n",
        "                                    initializer='uniform',\n",
        "                                    trainable=True)\n",
        "        self.node_vectors = {}\n",
        "        for i in range(1, self.output_dim):\n",
        "            self.node_vectors[i] = self.add_weight(name=\"node_\"+str(i),\n",
        "                                                   shape=(len(self.tree), len(self.tree)),\n",
        "                                                   initializer='uniform',\n",
        "                                                   trainable=True)\n",
        "        self.leaf_weight = {}\n",
        "        print self.leaf_path.keys()\n",
        "        for leaf_i in self.leaf_path.keys():\n",
        "            temp = []\n",
        "            #print leaf_i,\" : \",\n",
        "            for node in self.leaf_path[leaf_i]:\n",
        "                #print node, self.node_vectors[node], \"  ,\",\n",
        "                temp.append(self.node_vectors[node])\n",
        "            #print \"\"\n",
        "                \n",
        "            self.leaf_weight[leaf_i] = temp\n",
        "                \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}